{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pexels_api python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "\n",
    "from pexels_api import API\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# set up API\n",
    "api = API(\"NML9LYjorpAVsQdHb6g8eRMzwNajuoTl0QxwdB85aWN2OkE6iBYMmCRu\")\n",
    "\n",
    "# set up search criteria\n",
    "search_terms = ['lemon', 'lychee', 'grape', 'kiwi', 'apple'] # keywords for search\n",
    "num_images = 150 # number of images to download for each keyword\n",
    "page_size = 80 # maximum number of images per page\n",
    "\n",
    "# loop through each search term\n",
    "for term in search_terms:\n",
    "    # create folder to save images and CSV file\n",
    "    folder_name = f'{term}_images'\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    csv_file = os.path.join(folder_name, f'{term}_urls.csv')\n",
    "    \n",
    "    # search for images based on term\n",
    "    photos = []\n",
    "    for page in range(1, (num_images // page_size) + 2):\n",
    "        results = api.search(term, page=page, results_per_page=page_size)['photos']\n",
    "        if not results:\n",
    "            break\n",
    "        photos.extend(results)\n",
    "        if len(photos) >= num_images:\n",
    "            break\n",
    "    photos = photos[:num_images]\n",
    "\n",
    "    # save URLs to CSV file\n",
    "    with open(csv_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['image_id', 'image_url'])\n",
    "        for i, photo in enumerate(photos):\n",
    "            image_id = f'{term}_{i}'\n",
    "            image_url = photo['src']['original']\n",
    "            writer.writerow([image_id, image_url])\n",
    "            print(f'Saved URL for {image_id} to {csv_file} file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import requests\n",
    "\n",
    "# set up search criteria\n",
    "search_terms = ['lemon', 'lychee', 'grape', 'kiwi', 'apple'] # keywords for search\n",
    "\n",
    "# loop through each search term\n",
    "for term in search_terms:\n",
    "    # read CSV file to get image URLs and image IDs\n",
    "    csv_file = os.path.join(f'{term}_images', f'{term}_urls.csv')\n",
    "    with open(csv_file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader) # skip header row\n",
    "        for row in reader:\n",
    "            image_id = row[0]\n",
    "            image_url = row[1]\n",
    "            response = requests.get(image_url)\n",
    "            file_name = os.path.basename(image_url)\n",
    "            file_ext = os.path.splitext(file_name)[1]\n",
    "            file_name = f'{image_id}{file_ext}'\n",
    "            file_path = os.path.join(f'{term}_images', file_name)\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "                print(f'Saved {file_name} to {term}_images folder.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# set up search criteria\n",
    "search_terms = ['lemon', 'lychee', 'grape', 'kiwi', 'apple'] # keywords for search\n",
    "\n",
    "# set up parameters\n",
    "img_size = (128, 128) # size to resize images\n",
    "num_classes = len(search_terms) # number of fruit classes\n",
    "\n",
    "# load images and labels\n",
    "images = []\n",
    "labels = []\n",
    "for i, term in enumerate(search_terms):\n",
    "    folder_name = f'{term}_images'\n",
    "    for filename in os.listdir(folder_name):\n",
    "        image_path = os.path.join(folder_name, filename)\n",
    "        try:\n",
    "            # read image and resize\n",
    "            img = cv2.imread(image_path)\n",
    "            img = cv2.resize(img, img_size)\n",
    "            images.append(img)\n",
    "            labels.append(i)\n",
    "        except Exception as e:\n",
    "            print(f'Error loading {image_path}: {e}')\n",
    "\n",
    "# convert to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# convert labels to categorical\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_size[0], img_size[1], 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
